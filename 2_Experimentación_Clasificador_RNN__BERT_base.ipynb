{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAF7nxioSs-3",
        "outputId": "5d16b15d-1a4c-46a1-f979-9c801e176b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZobgHi4ZQUS"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNfam0rY_Pk"
      },
      "outputs": [],
      "source": [
        "#data = pickle.load(open('/content/drive/MyDrive/Tofi_BERT_base_uncased.pickle', 'rb'))\n",
        "data = pickle.load(open('/content/drive/MyDrive/BB_wstpw.pickle', 'rb'))\n",
        "\n",
        "X=data[0]\n",
        "Y=data[1]\n",
        "Sentence_embeddings=data[2]#.astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR3VTUbVaaGa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "Sentence_embeddings_=[]\n",
        "for k in range (len(Sentence_embeddings)):\n",
        "  x= np.reshape(Sentence_embeddings[k], (1, len(Sentence_embeddings[k])), order='C')\n",
        "  Sentence_embeddings_.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j51DTH2Ubd1A",
        "outputId": "bdccb970-f13a-4976-dfb9-344132e61960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.70994431e-01,  1.48704752e-01,  2.13716879e-01,\n",
              "         2.46226311e-01,  3.81293446e-01, -5.09013534e-01,\n",
              "         1.02944292e-01,  2.77625710e-01,  3.94395500e-01,\n",
              "        -2.60392398e-01, -3.74544710e-01, -1.48146346e-01,\n",
              "        -4.63762283e-01,  4.63701665e-01, -7.83945993e-02,\n",
              "         4.08785909e-01,  1.20891199e-01, -3.16295587e-02,\n",
              "         1.14950016e-01,  4.15455788e-01,  5.18638380e-02,\n",
              "         2.36717779e-02,  1.71536431e-01,  3.75136584e-01,\n",
              "         3.62990052e-01, -2.75604248e-01, -7.00308904e-02,\n",
              "         2.93498188e-01, -3.07543606e-01,  4.04392093e-01,\n",
              "         2.40685061e-01,  2.71326751e-01, -4.05874252e-01,\n",
              "        -2.57346690e-01,  2.43179530e-01,  2.60501117e-01,\n",
              "        -3.42585891e-02, -4.08031315e-01, -6.31151855e-01,\n",
              "         2.20110923e-01, -4.45665926e-01, -7.72905946e-02,\n",
              "        -1.52304238e-02,  3.20176780e-01, -2.79285740e-02,\n",
              "         1.94691345e-01,  5.61576307e-01, -7.89129734e-02,\n",
              "        -1.12513579e-01, -4.56089437e-01, -2.48351112e-01,\n",
              "         1.09182201e-01, -2.92510301e-01,  1.25524014e-01,\n",
              "         3.26557979e-02,  6.99498177e-01, -4.55346555e-01,\n",
              "        -2.94356108e-01, -3.10270876e-01,  1.23432934e-01,\n",
              "        -2.27136239e-01, -4.01802361e-01, -4.31713015e-01,\n",
              "        -2.23762229e-01,  1.17687389e-01,  2.39279106e-01,\n",
              "        -1.95853844e-01,  2.18316719e-01, -2.34906197e-01,\n",
              "         2.08772749e-01, -2.42961958e-01,  1.36697814e-01,\n",
              "        -4.02287543e-01,  1.53041735e-01, -2.14827910e-01,\n",
              "         6.81136727e-01, -7.72524923e-02,  1.43849745e-01,\n",
              "        -4.14977759e-01,  2.50878721e-01, -2.38775089e-01,\n",
              "         7.27099240e-01, -1.86267287e-01,  3.49608034e-01,\n",
              "         1.00036465e-01, -2.82147108e-03,  3.42751257e-02,\n",
              "         4.09423798e-01, -3.56489599e-01,  6.46892965e-01,\n",
              "        -9.11874250e-02,  1.56422466e-01,  1.44068956e-01,\n",
              "         2.89845705e-01,  4.51034069e-01, -2.09689766e-01,\n",
              "         7.66983449e-01, -2.19320878e-01,  3.44044389e-03,\n",
              "         4.19219553e-01,  2.95734733e-01, -5.11745453e-01,\n",
              "        -1.24330632e-01,  3.57774019e-01, -2.03799278e-01,\n",
              "        -1.22283556e-01, -1.04227260e-01,  2.46047564e-02,\n",
              "         6.99511021e-02,  6.20638486e-03,  3.77282172e-01,\n",
              "        -5.58827035e-02,  2.57319603e-02, -4.39085186e-01,\n",
              "        -1.07656367e-01, -2.00660467e-01, -2.48480186e-01,\n",
              "        -1.49705065e-02, -8.56105685e-02, -6.38283789e-02,\n",
              "         2.50891149e-01,  1.10612012e-01, -8.88634324e-02,\n",
              "         6.28004253e-01, -3.15789610e-01,  5.73341250e-02,\n",
              "        -2.23736819e-02,  2.18229026e-01, -1.35772139e-01,\n",
              "        -6.64876252e-02,  3.68995517e-01,  3.71416628e-01,\n",
              "         4.95203823e-01, -6.17340505e-01, -1.38194472e-01,\n",
              "        -1.42404661e-01,  2.54917406e-02, -2.22960979e-01,\n",
              "        -2.66234819e-02, -2.74896044e-02,  2.82468379e-01,\n",
              "        -1.13158427e-01,  1.69701815e-01, -3.01634163e-01,\n",
              "         2.52830088e-01, -9.95114818e-02, -2.21210212e-01,\n",
              "         2.31914166e-02,  2.22439185e-01,  5.50206661e-01,\n",
              "         1.82646111e-01, -2.74300247e-01, -3.14165056e-01,\n",
              "        -4.47293408e-02, -3.70873004e-01, -4.03032541e-01,\n",
              "         1.84366666e-02,  2.23222211e-01, -7.63333812e-02,\n",
              "        -2.48825625e-01,  1.74778804e-01, -1.02425896e-01,\n",
              "         2.76328269e-02,  2.02189997e-01, -3.10811829e-02,\n",
              "         1.76153883e-01, -5.25666699e-02,  3.74422550e-01,\n",
              "        -4.44561541e-01,  3.75963420e-01, -2.97027349e-01,\n",
              "        -3.41012180e-01,  7.83358574e-01, -1.71274289e-01,\n",
              "         4.23581749e-01, -1.92707792e-01,  2.56715089e-01,\n",
              "         3.01817894e-01,  6.16037726e-01,  8.79312530e-02,\n",
              "        -9.85153735e-01,  4.08592671e-01,  2.38299727e-01,\n",
              "         2.94396400e-01,  1.60373524e-01, -4.61789936e-01,\n",
              "         4.84552950e-01, -3.65749836e-01,  2.65378118e-01,\n",
              "        -5.43298662e-01, -5.30969799e-01, -2.66771466e-01,\n",
              "        -2.33129978e-01, -2.12207660e-01, -9.31801349e-02,\n",
              "        -9.72263366e-02, -6.17940910e-02, -4.15546477e-01,\n",
              "        -3.03570420e-01, -1.98287353e-01,  1.19253479e-01,\n",
              "         1.43092990e-01,  1.29907444e-01, -1.04719229e-01,\n",
              "        -2.06879646e-01, -1.18181281e-01,  4.34943348e-01,\n",
              "        -2.32158929e-01,  4.41522866e-01,  6.39363155e-02,\n",
              "         6.83416659e-03,  2.69752175e-01,  3.27563584e-01,\n",
              "        -3.07262421e-01, -3.95479910e-02, -1.54700473e-01,\n",
              "        -1.32648423e-01, -5.71448449e-03,  2.93178987e-02,\n",
              "         1.30095584e-02,  1.81195527e-01,  4.17151814e-03,\n",
              "        -2.87949473e-01,  5.04992068e-01,  2.63469182e-02,\n",
              "         7.34817803e-01,  1.53039321e-01, -2.73817867e-01,\n",
              "         1.25836730e-01,  1.05677199e+00, -3.15529183e-02,\n",
              "        -2.37625971e-01,  1.27163261e-01, -1.56158313e-01,\n",
              "        -2.14613095e-01, -6.95902854e-02, -8.43739137e-02,\n",
              "         5.35801984e-02,  1.09480619e-01, -5.14833510e-01,\n",
              "        -6.49158359e-01,  2.16919824e-01,  2.31154729e-02,\n",
              "         4.44830835e-01,  4.70544100e-02,  1.69683173e-01,\n",
              "         2.65011370e-01,  1.58435658e-01, -4.42796379e-01,\n",
              "        -1.98550537e-01, -2.45679006e-01, -4.99433100e-01,\n",
              "        -2.48026609e-01, -2.29928285e-01, -9.82394349e-03,\n",
              "        -4.09921795e-01, -2.57015437e-01,  1.74839735e-01,\n",
              "         1.97222643e-02, -5.03940403e-01, -3.63105461e-02,\n",
              "        -2.21105129e-01, -1.00143299e-01,  7.00163320e-02,\n",
              "        -4.42627221e-01, -7.57861733e-01,  2.68979639e-01,\n",
              "         1.50991216e-01, -3.15283127e-02,  1.13899224e-01,\n",
              "         2.46254548e-01, -1.29038677e-01,  1.36300936e-01,\n",
              "         6.08410358e-01, -3.47269565e-01,  1.16793895e-02,\n",
              "         3.71173412e-01,  2.09979430e-01, -4.57409054e-01,\n",
              "        -4.27733719e-01,  1.86427742e-01,  7.69964516e-01,\n",
              "        -3.29107821e-01,  1.46236494e-01, -4.56483901e-01,\n",
              "        -2.93901026e-01,  9.21681747e-02,  3.73473503e-02,\n",
              "        -3.70483458e-01, -3.92185599e-01, -5.10519445e-01,\n",
              "        -6.86853886e-01, -3.44626814e-01, -2.80563312e-04,\n",
              "         1.36742622e-01,  1.15597531e-01,  2.87843496e-01,\n",
              "         4.22753505e-02,  2.80426919e-01, -2.28851587e-01,\n",
              "         1.14139980e-02, -5.56133807e-01, -1.86460629e-01,\n",
              "         3.31633389e-01, -6.35175288e-01,  2.87244171e-02,\n",
              "        -3.08371753e-01, -2.70779312e-01, -4.16507626e+00,\n",
              "        -3.26024108e-02,  1.15130737e-01, -7.53123686e-02,\n",
              "         3.91632497e-01,  8.64082500e-02, -2.66923815e-01,\n",
              "        -2.59524971e-01, -2.66085804e-01,  2.86711395e-01,\n",
              "        -6.22261651e-02, -5.15600517e-02,  5.00634253e-01,\n",
              "         2.41243631e-01, -5.23220114e-02, -2.97766626e-02,\n",
              "         7.96848595e-01, -3.95810604e-01, -4.46971655e-02,\n",
              "         3.54602396e-01,  3.06101352e-01, -3.26866627e-01,\n",
              "        -2.20300749e-01, -3.17911059e-01,  4.79443401e-01,\n",
              "        -2.81568587e-01, -9.43206921e-02,  7.80116841e-02,\n",
              "        -2.34119967e-01, -2.28811100e-01,  2.89124250e-02,\n",
              "        -4.21015948e-01,  2.24890843e-01,  3.75445843e-01,\n",
              "         4.35556993e-02,  1.38603762e-01, -3.42624485e-01,\n",
              "        -8.69987831e-02, -5.30795380e-02, -3.14567149e-01,\n",
              "        -2.40863904e-01, -6.29449859e-02, -4.66853827e-01,\n",
              "        -1.06424995e-01,  6.40915692e-01,  9.40550193e-02,\n",
              "        -1.87331647e-01, -7.33729601e-02,  4.22622301e-02,\n",
              "         2.72570223e-01,  2.48988017e-01,  2.02943280e-01,\n",
              "        -3.10416490e-01,  3.95095870e-02, -1.71925481e-02,\n",
              "         5.32719970e-01,  6.15267575e-01,  3.31586748e-01,\n",
              "        -1.09655999e-01, -2.56900281e-01, -2.42412776e-01,\n",
              "         6.90763295e-02, -3.65838677e-01,  3.06260258e-01,\n",
              "        -1.60047427e-01, -1.64040849e-01, -4.29039955e-01,\n",
              "        -1.80400997e-01,  1.67960040e-02,  5.85724972e-02,\n",
              "        -1.92882083e-02,  6.82804942e-01, -2.13383511e-01,\n",
              "        -7.34910548e-01, -3.14486355e-01, -2.67867386e-01,\n",
              "         1.49456281e-02, -7.26533011e-02,  2.75734931e-01,\n",
              "        -2.23473459e-02, -3.27937037e-01, -7.31184408e-02,\n",
              "         1.51855230e-01, -2.16591328e-01,  3.08479011e-01,\n",
              "         1.04877241e-01,  2.29002073e-01,  2.56788939e-01,\n",
              "         2.91002095e-01, -3.23873252e-01,  2.17833415e-01,\n",
              "        -2.90001839e-01,  2.01763287e-01, -2.00011879e-02,\n",
              "        -5.50926663e-02,  2.44768396e-01,  2.30848864e-01,\n",
              "        -2.46687178e-02, -2.76931114e-02,  9.47322883e-03,\n",
              "         1.18306078e-01, -6.07400164e-02,  5.90384364e-01,\n",
              "        -2.56865948e-01,  3.13333243e-01, -1.24274559e-01,\n",
              "        -2.72990644e-01, -6.18561730e-02, -6.35614842e-02,\n",
              "         7.91264549e-02,  7.47814253e-02, -1.80348918e-01,\n",
              "         5.02671778e-01, -5.14344990e-01,  2.33523488e-01,\n",
              "         1.22628830e-01,  2.32519433e-01,  4.29169118e-01,\n",
              "         9.73703489e-02, -8.25332850e-02,  4.93413359e-01,\n",
              "         5.02425849e-01, -1.06113069e-01, -6.82305932e-01,\n",
              "        -2.69102752e-01, -1.10350020e-01, -3.79754305e-01,\n",
              "         4.32466060e-01,  1.89841509e-01,  1.06221125e-01,\n",
              "        -3.46488684e-01, -3.69333565e-01, -1.08820699e-01,\n",
              "         2.23331884e-01, -6.25092536e-02,  5.13828397e-02,\n",
              "         5.05679585e-02, -4.42348957e-01, -2.34774783e-01,\n",
              "         9.06112716e-02, -1.62998810e-01,  1.81439638e-01,\n",
              "        -2.22318187e-01, -3.33068937e-01,  1.74709871e-01,\n",
              "         3.70216519e-01,  1.40738159e-01,  1.00308575e-01,\n",
              "        -1.01916373e-01,  1.30263269e-01, -6.24263808e-02,\n",
              "        -7.51110241e-02, -7.65049234e-02, -4.01198566e-01,\n",
              "        -4.98553850e-02,  1.73646599e-01,  2.53829211e-01,\n",
              "         2.61555821e-01,  1.90158859e-01, -5.82397163e-01,\n",
              "         1.91700384e-01,  2.13802546e-01, -1.66472346e-01,\n",
              "         1.56362787e-01, -5.37650168e-01,  8.04106534e-01,\n",
              "         5.48696853e-02, -3.67839672e-02, -2.25232020e-01,\n",
              "         4.38288748e-01, -1.96933672e-01, -4.88611877e-01,\n",
              "        -1.55439496e-01, -6.08735025e-01,  9.21674520e-02,\n",
              "         5.38416743e-01, -4.05020118e-02, -2.06259191e-02,\n",
              "        -3.32356356e-02, -7.04447031e-02,  7.27980137e-02,\n",
              "        -4.19814616e-01, -3.94413263e-01, -3.67226392e-01,\n",
              "         2.27864102e-01, -1.43424541e-01,  3.78582440e-02,\n",
              "        -3.23499106e-02,  2.59450167e-01, -1.27609000e-01,\n",
              "         1.69518471e-01,  4.88802269e-02, -5.05745232e-01,\n",
              "        -7.50279278e-02, -2.74704993e-01, -3.29328567e-01,\n",
              "         5.62664866e-01,  1.53501118e-02, -2.91867517e-02,\n",
              "         2.40852699e-01,  1.79209739e-01, -3.28095227e-01,\n",
              "        -2.43325457e-01,  1.17320143e-01,  8.40128809e-02,\n",
              "        -1.38040334e-01, -4.38196659e-01,  3.40146840e-01,\n",
              "         3.08072604e-02,  9.38720480e-02, -4.87450138e-03,\n",
              "        -7.00594261e-02, -3.53404135e-01, -1.52535439e-02,\n",
              "         2.77931035e-01, -1.04175366e-01,  3.14237177e-01,\n",
              "        -1.23163406e-02, -8.45939592e-02, -1.10832853e-02,\n",
              "        -1.15386419e-01, -2.03879699e-01, -1.32423360e-02,\n",
              "         6.09350130e-02,  8.46932307e-02, -4.96904999e-01,\n",
              "         8.70433673e-02, -8.21678862e-02, -5.47080100e-01,\n",
              "        -2.28229865e-01,  3.77691798e-02, -4.31605816e-01,\n",
              "         3.37775461e-02,  1.65201262e-01,  1.02992214e-01,\n",
              "         4.55487639e-01,  1.48685485e-01, -3.61081839e-01,\n",
              "         3.34559120e-02, -8.54287818e-02, -2.75009777e-02,\n",
              "        -5.53353801e-02, -1.93931593e-03, -2.11282328e-01,\n",
              "        -1.55118138e-01, -9.55112129e-02, -3.32526602e-02,\n",
              "         5.80643117e-01, -1.11093007e-01,  1.37304053e-01,\n",
              "         1.73546925e-01, -4.37315032e-02, -2.26480529e-01,\n",
              "        -2.79321641e-01,  1.59445256e-01, -5.97688198e-01,\n",
              "        -1.49751669e-02, -4.29188192e-01, -3.25283051e-01,\n",
              "        -7.47793317e-02, -1.72241196e-01, -2.68178105e-01,\n",
              "         3.93390179e-01,  9.52640399e-02,  5.44230044e-01,\n",
              "        -1.35438845e-01, -1.05145201e-01, -1.13129709e-02,\n",
              "         2.54490942e-01, -6.84626997e-01,  1.01540647e-01,\n",
              "        -2.51582593e-01, -2.12120295e-01, -2.38288909e-01,\n",
              "        -1.66299790e-01,  3.58948797e-01,  3.92128490e-02,\n",
              "        -4.98368055e-01, -8.01530927e-02, -3.40778142e-01,\n",
              "        -2.44828984e-01,  2.06094697e-01, -1.61940426e-01,\n",
              "        -3.39870527e-02,  1.90078333e-01, -3.74689728e-01,\n",
              "        -3.20836216e-01,  2.59358436e-01, -4.29703534e-01,\n",
              "        -2.76483357e-01,  5.76269031e-01, -1.82884350e-01,\n",
              "        -2.62535512e-01, -3.43206413e-02, -8.73523392e-03,\n",
              "         1.90483809e-01,  2.39761993e-01,  1.97900429e-01,\n",
              "        -2.87528962e-01, -7.05179498e-02, -3.49655092e-01,\n",
              "         7.14957044e-02, -6.22154810e-02,  2.46773791e-02,\n",
              "        -2.22522527e-01,  2.18003377e-01,  5.11479713e-02,\n",
              "        -2.53054649e-01,  1.42735407e-01, -8.57549533e-02,\n",
              "         7.26626888e-02,  5.94497547e-02,  2.48177022e-01,\n",
              "         5.11713207e-01, -6.71261027e-02, -1.63624018e-01,\n",
              "        -8.87616724e-02, -1.37991965e-01,  5.87014072e-02,\n",
              "         2.98069000e-01,  5.35477139e-02,  1.76118985e-01,\n",
              "         4.47912633e-01, -2.02084079e-01,  8.86769965e-02,\n",
              "         3.22924942e-01, -1.13590464e-01, -8.64231773e-03,\n",
              "        -2.04267740e-01,  8.78222659e-02,  4.61035781e-02,\n",
              "         3.78025979e-01,  8.36813599e-02,  3.15752685e-01,\n",
              "        -1.22944750e-01, -1.29864797e-01, -3.01138572e-02,\n",
              "         2.38046095e-01,  3.09847593e-02, -1.54134244e-01,\n",
              "         2.88533628e-01,  2.03888148e-01,  4.10943776e-01,\n",
              "         4.26759243e-01,  1.58745989e-01,  1.44236758e-01,\n",
              "         2.01420620e-01, -2.13088349e-01,  3.30308467e-01,\n",
              "         1.50876939e-02, -4.07351367e-02, -1.02297980e-02,\n",
              "        -2.25760311e-01,  1.44703716e-01,  5.14303371e-02,\n",
              "         4.63032097e-01, -5.98112727e-03,  2.69024163e-01,\n",
              "        -4.85252924e-02,  1.76030084e-01, -2.36031175e-01,\n",
              "         4.67037231e-01,  2.69885868e-01, -5.35339057e-01,\n",
              "         1.54789433e-01, -1.59697875e-01, -5.07002994e-02,\n",
              "        -5.07982850e-01, -2.48054668e-01, -1.97416246e-02,\n",
              "         2.00844511e-01,  9.92178172e-02, -2.03018561e-01,\n",
              "        -2.97878027e-01,  2.89892614e-01,  6.25068545e-01,\n",
              "        -1.85241736e-02,  9.32335407e-02, -5.82782738e-02,\n",
              "         2.96277255e-01,  7.29778782e-02,  4.03811455e-01,\n",
              "        -3.86837244e-01, -1.63178314e-02, -3.62543046e-01,\n",
              "        -1.33489504e-01,  1.91818606e-02,  1.54170200e-01,\n",
              "         8.78610983e-02, -2.97826052e-01,  2.94800669e-01,\n",
              "         1.93795010e-01,  9.67699513e-02,  1.38743833e-01,\n",
              "        -1.61566466e-01, -2.12540865e-01,  7.15004325e-01,\n",
              "        -2.25265518e-01,  1.66481450e-01,  1.26850456e-01,\n",
              "         2.04448730e-01, -1.11398801e-01, -6.26831278e-02,\n",
              "         5.28973520e-01,  2.16760352e-01,  6.77552968e-02,\n",
              "         3.35945413e-02,  2.63547331e-01, -1.27803847e-01,\n",
              "         1.46150604e-01,  2.39296168e-01,  3.58815670e-01,\n",
              "        -4.46109623e-01,  5.20736575e-02,  1.62599042e-01,\n",
              "        -1.34768099e-01, -3.39427531e-01, -1.03194758e-01,\n",
              "        -1.66290894e-01, -1.50143638e-01, -1.48572326e-01,\n",
              "        -2.44036406e-01,  4.77422886e-02,  2.62626886e-01,\n",
              "        -1.21121541e-01,  1.02042042e-01,  2.72564679e-01,\n",
              "         1.59687787e-01,  6.92275017e-02, -1.10013969e-01,\n",
              "        -4.50541787e-02,  6.28029779e-02, -6.45150021e-02,\n",
              "         3.21940929e-01, -3.76201421e-01, -2.14918479e-01,\n",
              "        -1.25669405e-01,  4.69350144e-02, -5.51735461e-01,\n",
              "        -3.99306715e-01,  4.25854295e-01,  1.18694596e-01,\n",
              "         1.37262329e-01,  4.94803227e-02,  5.92813909e-01,\n",
              "        -4.19485092e-01,  8.26112404e-02, -4.13836956e-01,\n",
              "         2.19940278e-03, -1.85399637e-01,  2.61023212e-02,\n",
              "        -5.28016947e-02, -2.78356582e-01,  2.02089280e-01,\n",
              "        -2.05721095e-01, -4.64819342e-01, -4.40450981e-02,\n",
              "        -1.39586732e-01,  1.03295334e-01,  2.37832852e-02]], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sentence_embeddings_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8x-Fi7vVctl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62f4jjmsVeUL"
      },
      "outputs": [],
      "source": [
        "from tkinter.constants import TRUE\n",
        "#KFold(n_splits=2, random_state=None, shuffle=False)\n",
        "kfold= StratifiedKFold(n_splits=10, random_state=False, shuffle=True).split(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8aiTZswVi9E",
        "outputId": "ba98bc8d-9915-457e-fdf8-17b1d985df1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 3363 374\n",
            "1 3363 374\n",
            "2 3363 374\n",
            "3 3363 374\n",
            "4 3363 374\n",
            "5 3363 374\n",
            "6 3363 374\n",
            "7 3364 373\n",
            "8 3364 373\n",
            "9 3364 373\n"
          ]
        }
      ],
      "source": [
        "K_train=[]\n",
        "K_test=[]\n",
        "\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "  print(k, len(train), len(test))\n",
        "  K_test.append(test)\n",
        "  K_train.append(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJ3NLFXVw14",
        "outputId": "d4f723f6-9307-4b84-9910-57e81a1745fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 3732, 3734, 3735])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K_train[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eqOgOXgV7_s",
        "outputId": "fb9ba17d-81a1-440b-87f6-7e494e03b39b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 3734, 3735, 3736])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuVZaYBkWb3P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhTv2hfrWOZx"
      },
      "outputs": [],
      "source": [
        "x_train_total=[]\n",
        "y_train_onehot_total=[]\n",
        "sentence_train_total=[]\n",
        "x_test_total=[]\n",
        "y_test_onehot_total=[]\n",
        "sentence_test_total=[]\n",
        "\n",
        "for K in range (10):\n",
        "  x_train=[]\n",
        "  y_train_onehot=[]\n",
        "  sentence_train=[]\n",
        "  x_test=[]\n",
        "  y_test_onehot=[]\n",
        "  sentence_test=[]\n",
        "\n",
        "  K=0\n",
        "  for i  in range (3363):\n",
        "    n=K_train[K][i]\n",
        "    Se=Sentence_embeddings_[n].astype('float64')\n",
        "    x_train.append(Se.tolist())\n",
        "    sentence_train.append(X[n])\n",
        "    y_train_onehot.append(Y[n].astype('float64'))\n",
        "\n",
        "  for j in range (373):\n",
        "    n_=K_test[K][j]\n",
        "    se1= Sentence_embeddings_[n_].astype('float64')\n",
        "    x_test.append(se1.tolist())\n",
        "    sentence_test.append(X[n_])\n",
        "    y_test_onehot.append(Y[n_].astype('float64'))\n",
        "\n",
        "  x_train_total.append(x_train)\n",
        "  y_train_onehot_total.append(y_train_onehot)\n",
        "  sentence_train_total.append(sentence_train)\n",
        "  x_test_total.append(x_test)\n",
        "  y_test_onehot_total.append(y_test_onehot)\n",
        "  sentence_test_total.append(sentence_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swpek3iYWLnZ"
      },
      "outputs": [],
      "source": [
        "x_train= x_train_total[0]\n",
        "y_train_onehot=y_train_onehot_total[0]\n",
        "sentence_train=sentence_train_total[0]\n",
        "x_test= x_test_total[0]\n",
        "y_test_onehot= y_test_onehot_total[0]\n",
        "sentence_test= sentence_test_total[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmv5Iw3uYawS",
        "outputId": "24cf4924-eef8-4a3a-a69d-a8bc93f116f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(x_test[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw0XW4zmVDu6",
        "outputId": "045e0410-dcfd-4858-a833-0847e5aef545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.3\n"
          ]
        }
      ],
      "source": [
        "from tensorboard import version; print(version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJQ0BdY3iIt-"
      },
      "outputs": [],
      "source": [
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsIoBE5gdoCA"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import Dense, Flatten, TimeDistributed, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq9hG2qPiOFd",
        "outputId": "230779b6-0fc9-431c-9df6-3091f331a6e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 256)            1049600   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,246,849\n",
            "Trainable params: 1,246,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "xmodel= Sequential()\n",
        "#xmodel.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(1, 768)))\n",
        "#xmodel.add(Bidirectional(LSTM(128)))\n",
        "xmodel.add(LSTM(256, input_shape= (1, 768), return_sequences=True))\n",
        "xmodel.add(LSTM(128, return_sequences=False))\n",
        "xmodel.add(Dense(1))\n",
        "xmodel.build()\n",
        "xmodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgCokZZQjj5W",
        "outputId": "aba1aac9-5586-491b-bbec-5ede9f749449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lstm/lstm_cell/kernel:0 --> (768, 1024)\n",
            "lstm/lstm_cell/recurrent_kernel:0 --> (256, 1024)\n",
            "lstm/lstm_cell/bias:0 --> (1024,)\n"
          ]
        }
      ],
      "source": [
        "#print all matrices\n",
        "for x in xmodel.layers[0].weights:\n",
        "  print(x.name, '-->', x.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECZVG6ltlBTJ"
      },
      "outputs": [],
      "source": [
        "xmodel.compile(optimizer='adam',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_lMe3aZ_EAo",
        "outputId": "08e1f1ca-3ecf-4a75-a9dd-a97fedcefb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.8947\n",
            "Testing Accuracy:  0.8418\n"
          ]
        }
      ],
      "source": [
        "xmodel.fit(x_train, y_train_onehot,\n",
        "                     epochs=50,\n",
        "                     verbose=False,\n",
        "                     validation_data=(x_test, y_test_onehot),\n",
        "                     batch_size=100)\n",
        "loss, accuracy = xmodel.evaluate(x_train, y_train_onehot, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = xmodel.evaluate(x_test, y_test_onehot, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln73JoQTieYN",
        "outputId": "48a8c7dc-76aa-48d7-aa84-8277dcdcb5fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 874ms/step\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "[[0.45751503]\n",
            " [1.2961941 ]\n",
            " [0.9818148 ]\n",
            " [2.153275  ]\n",
            " [0.95008546]]\n"
          ]
        }
      ],
      "source": [
        "predictions= xmodel.predict(x_test[200:205])\n",
        "print(y_test_onehot[200:205])\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UaW6lHolFv_"
      },
      "outputs": [],
      "source": [
        "def clasificar(test_, s, l):\n",
        "  literal=0\n",
        "  metafora=0\n",
        "  Falseliteral=0\n",
        "  Falsemetafora=0\n",
        "\n",
        "  predictions= xmodel.predict(test_)\n",
        "  longt= len(test_)\n",
        "  for i in range(len(predictions)):\n",
        "    prob= predictions[i]\n",
        "    clasification= l[i]\n",
        "    if prob<=.51 and clasification==0:\n",
        "      #print(s[i], 'cLASSIFICATION: literal', 'CLASS:', l[i] ) # probabiidaad <.5 de que sea 1 es = literal\n",
        "      literal= literal+1\n",
        "    if prob<=.51 and clasification!=0:\n",
        "      #print(s[i], 'cLASSIFICATION: literal', 'CLASS:', l[i] ) # probabiidaad <.5 de que sea 1 (literal) mal clasificado\n",
        "      Falseliteral= Falseliteral+1\n",
        "    if prob>=.51 and clasification==1:\n",
        "      #print(s[i], 'CLASIFICATION: metaphore', 'CLASS:', l[i] ) #probabilidad de que sea >.5 de que sea metafora\n",
        "      metafora= metafora+1\n",
        "    if prob>=.51 and clasification!=1:\n",
        "      #print(s[i], 'CLASIFICATION: metaphore', 'CLASS:', l[i] ) #probabilidad de que sea metafora >.5\n",
        "      Falsemetafora= Falsemetafora+1\n",
        "  #loss, accuracy = xmodel.evaluate(test_, l, verbose=False)\n",
        "  print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "  #loss, accuracy = xmodel.evaluate(test_, l, verbose=False)\n",
        "  print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "  print(\"REULTADO FINAL:\", 'Metafora', metafora)\n",
        "  print(\"REULTADO FINAL:\", 'FalseMetafora', Falsemetafora)\n",
        "  print(\"REULTADO FINAL:\", 'Literal', literal)\n",
        "  print(\"REULTADO FINAL:\", 'FalseLiteral', Falseliteral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMUkcar0DFT8",
        "outputId": "cf0a05f4-97a6-4236-841a-0cfdef46f54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Training Accuracy: 0.6821\n",
            "Testing Accuracy:  0.6971\n",
            "1\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8177\n",
            "2\n",
            "Training Accuracy: 0.9932\n",
            "Testing Accuracy:  0.8391\n",
            "3\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8418\n",
            "4\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8284\n",
            "5\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8552\n",
            "6\n",
            "Training Accuracy: 0.9923\n",
            "Testing Accuracy:  0.8418\n",
            "7\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8391\n",
            "8\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8150\n",
            "9\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8177\n"
          ]
        }
      ],
      "source": [
        "for K in range (10):\n",
        "\n",
        "\n",
        "  print(K)\n",
        "  x_train= x_train_total[K]\n",
        "  y_train_onehot=y_train_onehot_total[K]\n",
        "  sentence_train=sentence_train_total[K]\n",
        "  x_test= x_test_total[K]\n",
        "  y_test_onehot= y_test_onehot_total[K]\n",
        "  sentence_test= sentence_test_total[K]\n",
        "\n",
        "  xmodel.fit(x_train, y_train_onehot,\n",
        "                     epochs=50,\n",
        "                     verbose=False,\n",
        "                     validation_data=(x_test, y_test_onehot),\n",
        "                     batch_size=100)\n",
        "  loss, accuracy = xmodel.evaluate(x_train, y_train_onehot, verbose=False)\n",
        "  print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "  loss, accuracy = xmodel.evaluate(x_test, y_test_onehot, verbose=False)\n",
        "  print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "  #clasificar(x_test, sentence_test , y_test_onehot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1UY8YUexCQx",
        "outputId": "4df3cb10-7e92-440a-8590-405706192e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "1\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "2\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "3\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "4\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "5\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "6\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "7\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "8\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n",
            "9\n",
            "Training Accuracy: 0.9938\n",
            "Testing Accuracy:  0.8204\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  class 0 literal     0.7888    0.7937    0.7913       160\n",
            "class 1 metafora      0.8443    0.8404    0.8424       213\n",
            "\n",
            "         accuracy                         0.8204       373\n",
            "        macro avg     0.8166    0.8171    0.8168       373\n",
            "     weighted avg     0.8205    0.8204    0.8204       373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "for K in range (10):\n",
        "  #K=5\n",
        "  print(K)\n",
        "  x_train= x_train_total[K]\n",
        "  y_train_onehot=y_train_onehot_total[K]\n",
        "  sentence_train=sentence_train_total[K]\n",
        "  x_test= x_test_total[K]\n",
        "  y_test_onehot= y_test_onehot_total[K]\n",
        "  sentence_test= sentence_test_total[K]\n",
        "  xmodel.fit(x_train, y_train_onehot,\n",
        "                      epochs=10,\n",
        "                      verbose=False,\n",
        "                      validation_data=(x_test, y_test_onehot),\n",
        "                      batch_size=100)\n",
        "  loss, accuracy = xmodel.evaluate(x_train, y_train_onehot, verbose=False)\n",
        "  print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "  loss, accuracy = xmodel.evaluate(x_test, y_test_onehot, verbose=False)\n",
        "  print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "  pred= xmodel.predict(x_test)\n",
        "  #print(pred[0])\n",
        "  new=[]\n",
        "  lit=0\n",
        "  met=0\n",
        "  labels=[]\n",
        "\n",
        "  ##0 es literal y 1 es metafora\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i]<=.50:\n",
        "        new.append(0)\n",
        "        lit= lit+1\n",
        "    if pred[i]>.50:\n",
        "        new.append(1)\n",
        "        met= met+1\n",
        "  #print('len', len(new))\n",
        "\n",
        "  for j in range (len(y_test_onehot)):\n",
        "    if y_test_onehot[j]==0:\n",
        "      labels.append(0)\n",
        "    else:\n",
        "      labels.append(1)\n",
        "\n",
        "\n",
        "  target_names = ['class 0 literal', 'class 1 metafora ']\n",
        "  print(classification_report(labels, new, target_names=target_names, digits=4))\n",
        "\n",
        "\n",
        "  #########"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}